# 머신러닝 분류 모델: 의사결정나무 & 랜덤포레스트

## 개요

### 의사결정나무 (Decision Tree)
의사결정나무는 데이터를 트리 구조로 분할하여 예측 또는 분류를 수행하는 지도 학습 알고리즘입니다. 각 노드는 데이터의 특정 특징에 따라 분기하며, 최종 리프 노드에서 예측 결과를 제공합니다.

![Decision Tree](./images/decision-tree.png)

- **노드 분할 기준**: Gini 지수, 엔트로피, 카이제곱 등을 사용하여 데이터를 분할.
- **과적합 방지**: 
  - 가지치기(pruning)
  - 최대 깊이 설정
  - 최소 샘플 수 설정
- **장점**:
  - 해석이 쉬움 (결과를 트리 구조로 시각화 가능)
  - 범주형 및 연속형 데이터 모두 처리 가능
- **단점**:
  - 과적합(overfitting) 위험이 있음
  - 데이터에 민감하여, 작은 변화에도 트리가 크게 변할 수 있음

### 랜덤포레스트 (Random Forest)
랜덤포레스트는 여러 개의 의사결정나무를 결합하여 예측력을 향상시키는 앙상블 학습 기법입니다. 각 트리는 데이터의 무작위 샘플링과 특징 선택을 통해 독립적으로 학습됩니다.

![Random Forest](./images/random-forest.png)

- **Bootstrap Aggregation**: 데이터의 부트스트랩 샘플링을 통해 각 트리 학습.
- **무작위성 도입**:
  - 각 노드에서 무작위로 선택된 일부 특징을 사용하여 분할.
- **앙상블 예측**:
  - 분류 문제: 다수결 투표(voting)
  - 회귀 문제: 평균(averaging)
- **장점**:
  - 과적합 방지
  - 높은 예측 정확도
  - 이상치 및 노이즈에 강건함
- **단점**:
  - 학습 속도가 느릴 수 있음
  - 개별 트리의 해석이 어려움

---

## 알고리즘 개념

### 1. 엔트로피
- **정의**: 무직위로 선택한 데이터 집합에서의 불확실성을 나타내는 지표

### 2. Gini 지수
- **정의**: 무작위로 선택한 데이터 집합에서 잘못

### 3. 카이제곱 검정
- **정의**: 두 범주형 변수 사이의 독립성 여부를 검정하는 통계적 방법

### 4. 부트스트랩 샘플링
- **정의**: 복원 추출을 통해 데이터 집합을 샘플링하는 방법

---

## 주요 파라미터

### 의사결정나무
| 파라미터          | 설명                            |
|-------------------|---------------------------------|
| `criterion`       | 분할 품질 기준 (`gini`, `entropy`) |
| `max_depth`       | 트리의 최대 깊이 설정           |
| `min_samples_split` | 노드 분할을 위한 최소 샘플 수  |

### 랜덤포레스트
| 파라미터               | 설명                                   |
|------------------------|----------------------------------------|
| `n_estimators`         | 생성할 트리의 개수                    |
| `max_features`         | 각 노드에서 고려할 최대 특징 수       |
| `max_depth`            | 개별 트리의 최대 깊이 설정            |
| `bootstrap`            | 부트스트랩 샘플링 여부 (`True`/`False`) |

---
